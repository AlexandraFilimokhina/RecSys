{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm \n",
    "import multiprocessing\n",
    "from copy import deepcopy \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение эмбеддингов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "songs = pd.read_csv('songs.csv')\n",
    "songs_extra = pd.read_csv('song_extra_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Идентифицируем песню artist_name и ее name\n",
    "merged_songs = pd.merge(songs, songs_extra, on=['song_id', 'song_id'], how='left')\n",
    "merged_songs[\"artist_song\"] = merged_songs[['artist_name', 'name']].apply(lambda x: str(x['artist_name']) + '+' + str(x['name']), axis=1)\n",
    "train = train.loc[:, ['msno', 'song_id', 'target']].merge(merged_songs.loc[:, ['song_id', 'artist_song']], on='song_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запомним для стекинга \n",
    "frame = deepcopy(train)\n",
    "frame_np = frame.loc[:, ['msno', 'artist_song']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Берем те которых слушали\n",
    "train = train.loc[train.target == 1, ['msno', 'artist_song']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем хеши, чтобы все быстрее работало, для этого два словаря\n",
    "udict = {user_hash:i for i, user_hash in enumerate(train[\"msno\"].unique())}\n",
    "sdict = {song_hash:i for i, song_hash in enumerate(train[\"artist_song\"].unique())}\n",
    "train[\"msno\"] = train[\"msno\"].apply(lambda x: udict[x])\n",
    "train[\"artist_song\"] = train[\"artist_song\"].apply(lambda x: sdict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "# Составляем текст - для каждого пользователя - те песни которые он слушал\n",
    "text = []\n",
    "X = train.to_numpy()\n",
    "for user in tqdm(train.msno.unique(), position=0,leave=False):\n",
    "    one_user_songs = X[X[:, 0] == user][:, 1]\n",
    "    one_user_songs = [str(x) for x in one_user_songs] \n",
    "    text.append(one_user_songs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эмбеддинги для песен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим CBOW \n",
    "model = Word2Vec(window=10,\n",
    "                 size=100,\n",
    "                 negative=15,\n",
    "                 min_count=1,\n",
    "                 sg=0,\n",
    "                 workers = multiprocessing.cpu_count())\n",
    "\n",
    "model.build_vocab(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min, sys: 4.15 s, total: 34min 4s\n",
      "Wall time: 3min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(371304309, 371465600)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.train(text, total_examples=model.corpus_count, epochs=100, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in set(sdict):\n",
    "#     try:\n",
    "#         if 'Eminem' in s:\n",
    "#             print(s)\n",
    "#     except:\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21387"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Берем Eminema и смотрим какие ему близки\n",
    "sdict['Eminem+Beautiful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_sdict = {j:i for i,j in sdict.items()}\n",
    "\n",
    "def get_most_similar(idx):\n",
    "    for sim in model.wv.most_similar(idx)[:5]:\n",
    "        print(f\"SCORE: {sim[1]:.2f}, {inverse_sdict[int(sim[0])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.62, Eminem+Mockingbird\n",
      "SCORE: 0.60, Eminem+When I'm Gone\n",
      "SCORE: 0.57, Eminem+Legacy\n",
      "SCORE: 0.57, Eminem+Cleanin' Out My Closet\n",
      "SCORE: 0.56, Eminem+Survival\n"
     ]
    }
   ],
   "source": [
    "get_most_similar('21387')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             \r"
     ]
    }
   ],
   "source": [
    "# Эмбеддинги для юзеров - берем среднее эмбеддингов песен, которые слушал пользователь \n",
    "user_embedings = {user : np.array([model.wv[str(i)] for i in text[i]]).mean(axis = 0)\n",
    "                  for user, i in tqdm(enumerate(train.msno.unique()), position=0, leave=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    }
   ],
   "source": [
    "# Добавляем скоры от эмбеддингов как доп фичу\n",
    "scores = []\n",
    "\n",
    "for row in tqdm(frame_np, position=0, leave=False):\n",
    "    u, s = row\n",
    "    score = 0\n",
    "    if (u in udict) and (s in sdict) and (udict[u] in user_embedings) and (f'{sdict[s]}' in model.wv):\n",
    "        score = np.sum(user_embedings[udict[u]] * model.wv[f'{sdict[s]}'])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['scores'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг эмбеддингов и фичей посчитанных в 1-ой части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'source_system_tab' : 'category',\n",
    "         'source_screen_name' : 'category',\n",
    "         'source_type' : 'category', \n",
    "         'genre_ids' : 'category',\n",
    "         'artist_name' : 'category'}\n",
    "\n",
    "part_1 = pd.read_csv('part_1.csv', dtype=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_embs = pd.merge(part_1, frame.drop(['target', 'artist_song'], axis=1),\n",
    "                     how='left', left_on=['msno', 'song_id'], right_on = ['msno', 'song_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = part_embs.drop(['target','msno', 'song_id', 'msno_artist', 'msno_genre', 'index',\n",
    "                    'country','genres_pop', 'country', 'gender', 'language'], axis=1)\n",
    "y = part_embs['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#уже не будем переподбирать параметры сравнимся на тех, что были подобраны в 1-ой части\n",
    "def k_fold_training(X, y, k=5):\n",
    "    aucs = []\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    for i, (train_ind, test_ind) in enumerate(kf.split(X, part_embs['msno'])):\n",
    "        print(f\"Folder {i+1}:\")\n",
    "    \n",
    "        X_train, y_train = X.iloc[train_ind], y.iloc[train_ind]\n",
    "        X_test, y_test = X.iloc[test_ind], y.iloc[test_ind]\n",
    "        \n",
    "        X_train, X_val, y_train, y_tval = train_test_split(X_train, y_train, test_size=0.2, random_state=10, stratify=y_train)\n",
    "\n",
    "        lgbtrain = lgb.Dataset(X_train, y_train)\n",
    "        lgbval = lgb.Dataset(X_val, y_tval)\n",
    "\n",
    "\n",
    "        params = {'objective': 'binary',\n",
    "                  'learning_rate': 0.27,\n",
    "                  'metric': 'auc',\n",
    "                  'max_depth': 10, \n",
    "                  'num_leaves': 256, \n",
    "                  'lambda_l1': 2.0,\n",
    "                  'lambda_l2': 2.5}\n",
    "\n",
    "        gbm = lgb.train(params, \n",
    "                          train_set=lgbtrain, \n",
    "                          num_boost_round=100, \n",
    "\n",
    "                          verbose_eval=25,\n",
    "                          valid_sets=[lgbtrain, lgbval],)\n",
    "        y_pred = gbm.predict(X_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        print(auc)\n",
    "        aucs.append(auc)\n",
    "   \n",
    "    print(f'Mean AUC_ROC: {np.mean(aucs):.3f} with {k} folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 1:\n",
      "[LightGBM] [Info] Number of positive: 2376403, number of negative: 2345144\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6355\n",
      "[LightGBM] [Info] Number of data points in the train set: 4721547, number of used features: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503310 -> initscore=0.013241\n",
      "[LightGBM] [Info] Start training from score 0.013241\n",
      "[25]\ttraining's auc: 0.792832\tvalid_1's auc: 0.783156\n",
      "[50]\ttraining's auc: 0.802695\tvalid_1's auc: 0.788673\n",
      "[75]\ttraining's auc: 0.81002\tvalid_1's auc: 0.792416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's auc: 0.816749\tvalid_1's auc: 0.795604\n",
      "0.7950830382067704\n",
      "Folder 2:\n",
      "[LightGBM] [Info] Number of positive: 2377393, number of negative: 2344154\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6327\n",
      "[LightGBM] [Info] Number of data points in the train set: 4721547, number of used features: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503520 -> initscore=0.014080\n",
      "[LightGBM] [Info] Start training from score 0.014080\n",
      "[25]\ttraining's auc: 0.793437\tvalid_1's auc: 0.782486\n",
      "[50]\ttraining's auc: 0.803673\tvalid_1's auc: 0.788359\n",
      "[75]\ttraining's auc: 0.81123\tvalid_1's auc: 0.792229\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's auc: 0.81641\tvalid_1's auc: 0.794382\n",
      "0.7944390120304488\n",
      "Folder 3:\n",
      "[LightGBM] [Info] Number of positive: 2378097, number of negative: 2343450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6401\n",
      "[LightGBM] [Info] Number of data points in the train set: 4721547, number of used features: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503669 -> initscore=0.014676\n",
      "[LightGBM] [Info] Start training from score 0.014676\n",
      "[25]\ttraining's auc: 0.794379\tvalid_1's auc: 0.783358\n",
      "[50]\ttraining's auc: 0.804251\tvalid_1's auc: 0.788754\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\ttraining's auc: 0.810564\tvalid_1's auc: 0.791815\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's auc: 0.815114\tvalid_1's auc: 0.793526\n",
      "0.7930116659601798\n",
      "Folder 4:\n",
      "[LightGBM] [Info] Number of positive: 2377281, number of negative: 2344267\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6339\n",
      "[LightGBM] [Info] Number of data points in the train set: 4721548, number of used features: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503496 -> initscore=0.013985\n",
      "[LightGBM] [Info] Start training from score 0.013985\n",
      "[25]\ttraining's auc: 0.79443\tvalid_1's auc: 0.782945\n",
      "[50]\ttraining's auc: 0.803582\tvalid_1's auc: 0.787912\n",
      "[75]\ttraining's auc: 0.810582\tvalid_1's auc: 0.791412\n",
      "[100]\ttraining's auc: 0.816204\tvalid_1's auc: 0.793949\n",
      "0.7942354398990903\n",
      "Folder 5:\n",
      "[LightGBM] [Info] Number of positive: 2377725, number of negative: 2343823\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6427\n",
      "[LightGBM] [Info] Number of data points in the train set: 4721548, number of used features: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/Alexandra.Filimokhina/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503590 -> initscore=0.014361\n",
      "[LightGBM] [Info] Start training from score 0.014361\n",
      "[25]\ttraining's auc: 0.793948\tvalid_1's auc: 0.783415\n",
      "[50]\ttraining's auc: 0.803816\tvalid_1's auc: 0.78891\n",
      "[75]\ttraining's auc: 0.810728\tvalid_1's auc: 0.792304\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's auc: 0.817861\tvalid_1's auc: 0.79604\n",
      "0.7960176247623457\n",
      "Mean AUC_ROC: 0.795 with 5 folds\n"
     ]
    }
   ],
   "source": [
    "k_fold_training(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#УРА! добавление эмбеддингов помогло увеличить скор с 0.748 до 0.795, что говорит о том, что это супер важная фича!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
