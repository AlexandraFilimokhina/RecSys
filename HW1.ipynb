{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матричные факторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе вам предстоит познакомиться с практической стороной матричных разложений.\n",
    "Работа поделена на 4 задания:\n",
    "1. Вам необходимо реализовать SVD разложения используя SGD на explicit данных\n",
    "2. Вам необходимо реализовать матричное разложения используя ALS на implicit данных\n",
    "3. Вам необходимо реализовать матричное разложения используя BPR(pair-wise loss) на implicit данных\n",
    "4. Вам необходимо реализовать матричное разложения используя WARP(list-wise loss) на implicit данных\n",
    "\n",
    "Мягкий дедлайн 28 Сентября (пишутся замечания, выставляется оценка, есть возможность исправить до жесткого дедлайна)\n",
    "\n",
    "Жесткий дедлайн 5 Октября (Итоговая проверка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/miniconda3/lib/python3.8/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from lightfm.datasets import fetch_movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе мы будем работать с explicit датасетом movieLens, в котором представленны пары user_id movie_id и rating выставленный пользователем фильму\n",
    "\n",
    "Скачать датасет можно по ссылке https://grouplens.org/datasets/movielens/1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.dat', delimiter='::', header=None, \n",
    "        names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "        usecols=['user_id', 'movie_id', 'rating'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = pd.read_csv('movies.dat', delimiter='::', header=None, \n",
    "        names=['movie_id', 'name', 'category'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  movie_id  rating\n",
       "0              1      1193       5\n",
       "1              1       661       3\n",
       "2              1       914       3\n",
       "3              1      3408       4\n",
       "4              1      2355       5\n",
       "...          ...       ...     ...\n",
       "1000204     6040      1091       1\n",
       "1000205     6040      1094       5\n",
       "1000206     6040       562       5\n",
       "1000207     6040      1096       4\n",
       "1000208     6040      1097       4\n",
       "\n",
       "[1000209 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы преобразовать текущий датасет в Implicit, давайте считать что позитивная оценка это оценка >=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_ratings = ratings.loc[(ratings['rating'] >= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  movie_id  rating\n",
       "0         1      1193       5\n",
       "3         1      3408       4\n",
       "4         1      2355       5\n",
       "6         1      1287       5\n",
       "7         1      2804       5\n",
       "8         1       594       4\n",
       "9         1       919       4\n",
       "10        1       595       5\n",
       "11        1       938       4\n",
       "12        1      2398       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удобнее работать с sparse матричками, давайте преобразуем DataFrame в CSR матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = implicit_ratings[\"user_id\"]\n",
    "movies = implicit_ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "user_item_t_csr = user_item.T.tocsr()\n",
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=64, iterations=100, calculate_training_loss=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве loss здесь всеми любимый RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd053da8b854e4ca3a582cf9c14de0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(user_item_t_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим похожие фильмы по 1 movie_id = Истории игрушек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                name                      category\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                        for x in model.similar_items(item_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, симилары действительно оказались симиларами.\n",
    "\n",
    "Качество симиларов часто является хорошим способом проверить качество алгоритмов.\n",
    "\n",
    "P.S. Если хочется поглубже разобраться в том как разные алгоритмы формируют разные латентные пространства, рекомендую загружать полученные вектора в tensorBoard и смотреть на сформированное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '33    Babe (1995)',\n",
       " '584    Aladdin (1992)',\n",
       " '2315    Babe: Pig in the City (1998)',\n",
       " '1526    Hercules (1997)',\n",
       " '360    Lion King, The (1994)',\n",
       " '2618    Tarzan (1999)',\n",
       " '1838    Mulan (1998)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь построим рекомендации для юзеров\n",
    "\n",
    "Как мы видим юзеру нравится фантастика, значит и в рекомендациях ожидаем увидеть фантастику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_history = lambda user_id, implicit_ratings : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() \n",
    "                                            for x in implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3399    Hustler, The (1961)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1196    Alien (1979)',\n",
       " '1023    Die Hard (1988)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1959    Saving Private Ryan (1998)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1885    Rocky (1976)',\n",
       " '1081    E.T. the Extra-Terrestrial (1982)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '3633    Mad Max (1979)',\n",
       " '2297    King Kong (1933)',\n",
       " '1366    Jaws (1975)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '2623    Run Lola Run (Lola rennt) (1998)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1220    Terminator, The (1984)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось! \n",
    "\n",
    "Мы действительно порекомендовали пользователю фантастику и боевики, более того встречаются продолжения тех фильмов, которые он высоко оценил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations = lambda user_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                               for x in model.recommend(user_id, user_item_csr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['585    Terminator 2: Judgment Day (1991)',\n",
       " '1271    Indiana Jones and the Last Crusade (1989)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '2502    Matrix, The (1999)',\n",
       " '1182    Aliens (1986)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '1892    Rain Man (1988)',\n",
       " '453    Fugitive, The (1993)',\n",
       " '1884    French Connection, The (1971)',\n",
       " '1179    Princess Bride, The (1987)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ваша очередь реализовать самые популярные алгоритмы матричных разложений\n",
    "\n",
    "Что будет оцениваться:\n",
    "1. Корректность алгоритма\n",
    "2. Качество получившихся симиларов\n",
    "3. Качество итоговых рекомендаций для юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations = lambda user_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                               for x in model.recommend(user_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Не использую готовые решения, реализовать SVD разложение используя SGD на explicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "    def __init__(self, df=ratings, n_users=ratings[\"user_id\"].max(), n_items=ratings[\"movie_id\"].max(), \n",
    "                 K=64, lr=0.01, lam=0.01, max_steps=int(100e6), step_check=int(1e5), eps=1e-7, init_bias=True):\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.data = self.df.to_numpy()\n",
    "\n",
    "        self.n_nonzero = self.data.shape[0]\n",
    "        self.n_users, self.n_items = n_users, n_items\n",
    "        self.unique_items = self.df[\"movie_id\"].unique()\n",
    "        self.unique_users = self.df[\"user_id\"].unique()   \n",
    "        \n",
    "        self.K = K # latent size\n",
    "        self.lr = lr # learning rate \n",
    "        self.lam = lam # regularization parameter\n",
    "        self.eps = eps # convergence threshold\n",
    "        self.max_steps = max_steps # max_steps\n",
    "        self.step_check = step_check # print every steps\n",
    "        \n",
    "        self.W = np.random.uniform(0, 1/np.sqrt(self.K), size=(self.n_users, self.K))  \n",
    "        self.H = np.random.uniform(0, 1/np.sqrt(self.K), size=(self.n_items, self.K))\n",
    "\n",
    "        self.V = None\n",
    "        \n",
    "        if init_bias:\n",
    "            self.bias = np.mean(self.data[:, 2])\n",
    "            self.W_bias = np.random.normal(3.5, size=(self.n_users, 1)) \n",
    "            self.H_bias = np.random.normal(3.5, size=(self.n_items, 1)) \n",
    "            \n",
    "                \n",
    "    def check_convergence(self, step, show=True):\n",
    "        \"\"\"\n",
    "        Calculate RMSE and check the convergence condition   \n",
    "        \"\"\"\n",
    "        R_predicted = self.V[self.data[:, 0] - 1, self.data[:, 1] - 1]\n",
    "        R_true = self.data[:, 2]\n",
    "        RMSE = np.linalg.norm(R_predicted - R_true)/self.n_nonzero\n",
    "        if show:\n",
    "            print(f\"[{step}] RMSE: {RMSE:.4}\")\n",
    "        return RMSE < self.eps \n",
    "            \n",
    "        \n",
    "    def similar_items(self, item_id, k=10):\n",
    "        \"\"\"\n",
    "        Get similar items for useritem_id according to fitted embeddings \n",
    "        \"\"\"\n",
    "        ratings = [(other_item_id, np.linalg.norm(self.H[item_id - 1] - self.H[other_item_id - 1]))\n",
    "                   for other_item_id in self.unique_items]\n",
    "        items_ratings = sorted(ratings, key=lambda x: x[1]) \n",
    "        return items_ratings[:k]\n",
    "        \n",
    "    def recommend(self, user_id, k=10):\n",
    "        \"\"\"\n",
    "        Recommend users new items which he didn't look before \n",
    "        \"\"\"\n",
    "        new_items_ids = list(set(self.unique_items) - set(self.df.loc[self.df[\"user_id\"] == user_id][\"movie_id\"]))\n",
    "        new_items_ratings = self.V[user_id - 1][np.array(new_items_ids) - 1]\n",
    "        items_ratings = sorted(list(zip(new_items_ids, new_items_ratings)), key=lambda x: x[1], reverse=True) \n",
    "        return items_ratings[:k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD(Base):\n",
    "    def __init__(self, df=ratings, n_users=ratings[\"user_id\"].max(), n_items=ratings[\"movie_id\"].max(), \n",
    "                 K=64, lr=0.01, lam=0.01, max_steps=int(100e6), step_check=int(1e5), eps=1e-7, init_bias=True):\n",
    "        Base.__init__(self, df, n_users, n_items, K, lr, lam, max_steps, step_check, eps, init_bias)\n",
    "        self.recommendation_mat()\n",
    "        \n",
    "    def recommendation_mat(self):\n",
    "        self.V = self.bias + self.W_bias + self.H_bias.T + self.W @ self.H.T\n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit SVD  \n",
    "        \"\"\"\n",
    "        for step in range(self.max_steps + 1):\n",
    "            \n",
    "            if step % self.step_check == 0:\n",
    "                self.recommendation_mat()\n",
    "                if self.check_convergence(step, show=True):\n",
    "                    self.recommendation_mat()\n",
    "                    break \n",
    "                \n",
    "            i, j, rating = self.data[np.random.randint(self.n_nonzero), :]\n",
    "            \n",
    "            i-=1\n",
    "            j-=1\n",
    "  \n",
    "            error = (self.bias + self.W_bias[i] + self.H_bias[j] + self.W[i, ]@self.H[j,].T) - rating\n",
    "            \n",
    "            self.W_bias[i, ] -= self.lr * (error + self.lam * self.W_bias[i, ])\n",
    "            self.H_bias[j, ] -= self.lr * (error + self.lam * self.H_bias[j, ])\n",
    "            \n",
    "            W_i = self.W[i, ][:]\n",
    "            \n",
    "            self.W[i, ] -= self.lr * (error * self.H[j, ] + self.lam * self.W[i, ]) \n",
    "            self.H[j, ] -= self.lr * (error * W_i + self.lam * self.H[j, ])  \n",
    "            \n",
    "        self.recommendation_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] RMSE: 0.007534\n",
      "[2000000] RMSE: 0.001003\n",
      "[4000000] RMSE: 0.0009241\n",
      "[6000000] RMSE: 0.000888\n",
      "[8000000] RMSE: 0.0008611\n",
      "[10000000] RMSE: 0.0008394\n",
      "[12000000] RMSE: 0.0008216\n",
      "[14000000] RMSE: 0.0008059\n",
      "[16000000] RMSE: 0.0007924\n",
      "[18000000] RMSE: 0.0007811\n",
      "[20000000] RMSE: 0.0007707\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(df=ratings, n_users=ratings[\"user_id\"].max(), n_items=ratings[\"movie_id\"].max(), \n",
    "          K=30, lr=0.01, lam=0.05, max_steps=int(20e6), step_check=int(20e5), eps=1e-6, init_bias=True)\n",
    "svd.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '584    Aladdin (1992)',\n",
       " '3682    Chicken Run (2000)',\n",
       " '3059    Map of the World, A (1999)',\n",
       " '1526    Hercules (1997)',\n",
       " '591    Beauty and the Beast (1991)',\n",
       " '3186    League of Their Own, A (1992)',\n",
       " '3027    My Man Godfrey (1957)']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1099    Sleepover (1995)',\n",
       " '3143    Born to Win (1971)',\n",
       " '1056    Macao (1952)',\n",
       " '1102    Tashunga (1995)',\n",
       " '1587    Lay of the Land, The (1997)',\n",
       " '1839    Resurrection Man (1998)',\n",
       " '651    Yankee Zulu (1994)',\n",
       " '2776    White Boys (1999)',\n",
       " '3208    Beloved/Friend (Amigo/Amado) (1999)',\n",
       " \"580    I Don't Want to Talk About It (De eso no se ha...\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3399    Hustler, The (1961)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1196    Alien (1979)',\n",
       " '1023    Die Hard (1988)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1959    Saving Private Ryan (1998)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1885    Rocky (1976)',\n",
       " '1081    E.T. the Extra-Terrestrial (1982)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '3633    Mad Max (1979)',\n",
       " '2297    King Kong (1933)',\n",
       " '1366    Jaws (1975)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '2623    Run Lola Run (Lola rennt) (1998)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1220    Terminator, The (1984)']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Не использую готовые решения, реализовать матричное разложение используя ALS на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS(Base):\n",
    "    def __init__(self, df=implicit_ratings, n_users=implicit_ratings[\"user_id\"].max(), n_items=implicit_ratings[\"movie_id\"].max(), \n",
    "                 K=30, lr=1e-3, lam=1e-3, max_steps=int(100), step_check=int(10), eps=1e-6, init_bias=False):\n",
    "        Base.__init__(self, df, n_users, n_items, K, lr, lam, max_steps, step_check, eps, init_bias)\n",
    "        self.recommendation_mat()\n",
    "\n",
    "    def recommendation_mat(self):\n",
    "        self.V = self.W @ self.H.T\n",
    "           \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit ALS \n",
    "        \"\"\"\n",
    "        for step in range(self.max_steps + 1):\n",
    "            self.recommendation_mat()\n",
    "            \n",
    "            if step % self.step_check == 0:\n",
    "                if self.check_convergence(step, show=True):\n",
    "                    self.recommendation_mat()\n",
    "                    break \n",
    "                    \n",
    "            error = self.V[:]\n",
    "            error[self.data[:, 0] - 1, self.data[:, 1] - 1] -= self.data[:, 2]\n",
    "            \n",
    "            if step % 2 == 0:\n",
    "                self.W -= self.lr * (error@self.H + self.lam * self.W)\n",
    "            else:\n",
    "                self.H -= self.lr * (error.T@self.W + self.lam * self.H)   \n",
    "                \n",
    "        self.recommendation_mat()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] RMSE: 0.005501\n",
      "[10] RMSE: 0.004802\n",
      "[20] RMSE: 0.004575\n",
      "[30] RMSE: 0.004317\n",
      "[40] RMSE: 0.004178\n",
      "[50] RMSE: 0.004067\n",
      "[60] RMSE: 0.004004\n",
      "[70] RMSE: 0.003974\n",
      "[80] RMSE: 0.003961\n",
      "[90] RMSE: 0.003953\n",
      "[100] RMSE: 0.003949\n"
     ]
    }
   ],
   "source": [
    "als = ALS()\n",
    "als.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '584    Aladdin (1992)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '33    Babe (1995)',\n",
       " '360    Lion King, The (1994)',\n",
       " '591    Beauty and the Beast (1991)',\n",
       " '1838    Mulan (1998)',\n",
       " '2252    Pleasantville (1998)',\n",
       " '1245    Groundhog Day (1993)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       " '847    Godfather, The (1972)',\n",
       " '1182    Aliens (1986)',\n",
       " '1271    Indiana Jones and the Last Crusade (1989)',\n",
       " '585    Terminator 2: Judgment Day (1991)',\n",
       " '1203    Godfather: Part II, The (1974)',\n",
       " '453    Fugitive, The (1993)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '3458    Predator (1987)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3399    Hustler, The (1961)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1196    Alien (1979)',\n",
       " '1023    Die Hard (1988)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1959    Saving Private Ryan (1998)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1885    Rocky (1976)',\n",
       " '1081    E.T. the Extra-Terrestrial (1982)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '3633    Mad Max (1979)',\n",
       " '2297    King Kong (1933)',\n",
       " '1366    Jaws (1975)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '2623    Run Lola Run (Lola rennt) (1998)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1220    Terminator, The (1984)']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Не использую готовые решения, реализовать матричное разложение BPR на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(Base):\n",
    "    def __init__(self, df=implicit_ratings, n_users=implicit_ratings[\"user_id\"].max(), n_items=implicit_ratings[\"movie_id\"].max(), \n",
    "                 K=30, lr=1e-1, lam=1e-3, max_steps=int(1e6), step_check=int(1e4), eps=1e-6, init_bias=False, sample=5):\n",
    "        Base.__init__(self, df, n_users, n_items, K, lr, lam, max_steps, step_check, eps, init_bias)\n",
    "        self.sample = sample\n",
    "        self.recommendation_mat()\n",
    "\n",
    "    def recommendation_mat(self):\n",
    "        self.V = self.W @ self.H.T\n",
    "        \n",
    "    def compute_pos_neg(self):\n",
    "        self.user_pos_neg = {}\n",
    "        for u in tqdm(self.unique_users):         \n",
    "            user_pos_items = self.data[self.data[:, 0] == u][:, 1]\n",
    "            user_neg_items = list(set(self.unique_items) - set(user_pos_items))\n",
    "            self.user_pos_neg[u] = (user_pos_items, user_neg_items)\n",
    "           \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit BPR\n",
    "        \"\"\"\n",
    "        self.compute_pos_neg() \n",
    "        for step in range(self.max_steps + 1):\n",
    "            \n",
    "            if step % self.step_check == 0:\n",
    "                self.recommendation_mat()\n",
    "                if self.check_convergence(step, show=True):\n",
    "                    self.recommendation_mat()\n",
    "                    break \n",
    "                   \n",
    "            for u in tqdm(self.unique_users):\n",
    "                user_pos_items, user_neg_items = self.user_pos_neg[u]\n",
    "                u -= 1\n",
    "                for i in user_pos_items:\n",
    "                    i -= 1\n",
    "                    neg_sample = np.random.choice(user_neg_items, size=self.sample, replace=False)\n",
    "                    \n",
    "                    for j in neg_sample:                        \n",
    "                        j -= 1\n",
    "                        r_ui = self.W[u]@self.H[i].T\n",
    "                        r_uj = self.W[u]@self.H[j].T\n",
    "\n",
    "                        L =  1 / (1 + np.exp(r_ui - r_uj))\n",
    "\n",
    "                        W_u = self.W[u][:]\n",
    "\n",
    "                        self.W[u] += self.lr * (L * (self.H[i] - self.H[j]) - self.lam * self.W[u])\n",
    "                        self.H[i] += self.lr * (L * W_u - self.lam * self.H[i])\n",
    "                        self.H[j] += self.lr * (L * (-W_u) - self.lam * self.H[j])                     \n",
    "                            \n",
    "        self.recommendation_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [00:11<00:00, 506.22it/s]\n",
      "  0%|          | 5/6038 [00:00<02:26, 41.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] RMSE: 0.005501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [04:41<00:00, 21.44it/s]\n",
      "  0%|          | 3/6038 [00:00<03:56, 25.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] RMSE: 0.003055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [04:41<00:00, 21.44it/s]\n",
      "  0%|          | 4/6038 [00:00<02:31, 39.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] RMSE: 0.00278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [04:25<00:00, 22.76it/s]\n",
      "  0%|          | 5/6038 [00:00<02:36, 38.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] RMSE: 0.002583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [04:27<00:00, 22.58it/s]\n",
      "  0%|          | 4/6038 [00:00<02:37, 38.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] RMSE: 0.002395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [04:42<00:00, 21.37it/s]\n",
      "  0%|          | 4/6038 [00:00<02:40, 37.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] RMSE: 0.002277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [04:35<00:00, 21.88it/s]\n"
     ]
    }
   ],
   "source": [
    "bpr = BPR(df=implicit_ratings, n_users=implicit_ratings[\"user_id\"].max(), n_items=implicit_ratings[\"movie_id\"].max(), \n",
    "          K=100, lr=0.01, lam=0.0001, max_steps=int(5), step_check=int(1), eps=1e-6, init_bias=True)\n",
    "bpr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '1179    Princess Bride, The (1987)',\n",
       " '1245    Groundhog Day (1993)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '1250    Back to the Future (1985)',\n",
       " '33    Babe (1995)',\n",
       " '1539    Men in Black (1997)',\n",
       " '584    Aladdin (1992)',\n",
       " '2918    Who Framed Roger Rabbit? (1988)']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, bpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '2502    Matrix, The (1999)',\n",
       " '2789    American Beauty (1999)',\n",
       " '847    Godfather, The (1972)',\n",
       " '585    Terminator 2: Judgment Day (1991)',\n",
       " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       " '2693    Sixth Sense, The (1999)',\n",
       " '589    Silence of the Lambs, The (1991)',\n",
       " '604    Fargo (1996)',\n",
       " '1575    L.A. Confidential (1997)']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, bpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Не использую готовые решения, реализовать матричное разложение WARP на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WARP(Base):\n",
    "    def __init__(self, df=implicit_ratings, n_users=implicit_ratings[\"user_id\"].max(), n_items=implicit_ratings[\"movie_id\"].max(), \n",
    "                 K=30, lr=1e-1, lam=1e-3, max_steps=int(1e6), step_check=int(1e4), eps=1e-6, init_bias=True, sample=5):\n",
    "        Base.__init__(self, df, n_users, n_items, K, lr, lam, max_steps, step_check, eps, init_bias)\n",
    "       \n",
    "        self.sample = sample\n",
    "        self.recommendation_mat()\n",
    "\n",
    "    def recommendation_mat(self):\n",
    "        self.V = self.W @ self.H.T\n",
    "        \n",
    "    def compute_pos_neg(self):\n",
    "        self.user_pos_neg = {}\n",
    "        for u in tqdm(self.unique_users):         \n",
    "            user_pos_items = self.data[self.data[:, 0] == u][:, 1]\n",
    "            user_neg_items = list(set(self.unique_items) - set(user_pos_items))\n",
    "            self.user_pos_neg[u] = (user_pos_items, user_neg_items)\n",
    "            \n",
    "    def r(self, user, item):\n",
    "        return self.W[user]@self.H[item].T\n",
    "    \n",
    "    def best_neg_sample(self, user, pos_item, user_neg_items, rank = 0):\n",
    "        r_ui = self.r(user, pos_item)\n",
    "        for _ in range(len(user_neg_items)):\n",
    "            j = np.random.choice(user_neg_items) - 1\n",
    "            r_uj = self.r(user, j)\n",
    "            rank += 1\n",
    "            if r_ui < r_uj + 1:\n",
    "                break \n",
    "        return j, np.log(len(user_neg_items) / rank) \n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit WARP\n",
    "        \"\"\"\n",
    "        self.compute_pos_neg() \n",
    "        for step in range(self.max_steps + 1):\n",
    "           \n",
    "            if step % self.step_check == 0:\n",
    "                self.recommendation_mat()\n",
    "                if self.check_convergence(step, show=True):\n",
    "                    self.recommendation_mat()\n",
    "                    break \n",
    "                   \n",
    "            for u in tqdm(self.unique_users):\n",
    "                user_pos_items, user_neg_items = self.user_pos_neg[u]\n",
    "                u -= 1\n",
    "                for i in user_pos_items:\n",
    "                    i -= 1\n",
    "                    j, weight = self.best_neg_sample(u, i, user_neg_items)\n",
    "\n",
    "                    W_u = self.W[u][:]\n",
    "\n",
    "                    self.W[u] += self.lr * (weight * (self.H[i] - self.H[j]) - self.lam * self.W[u])\n",
    "                    self.H[i] += self.lr * (weight * W_u - self.lam * self.H[i])\n",
    "                    self.H[j] += self.lr * (weight * (-W_u) - self.lam * self.H[j]) \n",
    "                            \n",
    "        self.recommendation_mat()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp = WARP(df=implicit_ratings, n_users=implicit_ratings[\"user_id\"].max(), n_items=implicit_ratings[\"movie_id\"].max(), \n",
    "          K=100, lr=0.01, lam=0.0001, max_steps=int(1), step_check=int(1), eps=1e-6, init_bias=False)\n",
    "warp.fit()\n",
    "#у меня супер долго училось и кажется где то ошибка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '591    Beauty and the Beast (1991)',\n",
       " '360    Lion King, The (1994)',\n",
       " '584    Aladdin (1992)',\n",
       " '2009    Jungle Book, The (1967)',\n",
       " '1262    Fantasia (1940)',\n",
       " '1246    Unforgiven (1992)',\n",
       " '2011    Lady and the Tramp (1955)',\n",
       " '1205    Grand Day Out, A (1992)',\n",
       " '2018    Peter Pan (1953)']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3411    Lucas (1986)',\n",
       " '2822    Happy, Texas (1999)',\n",
       " '2803    Excalibur (1981)',\n",
       " '2506    Dreamlife of Angels, The (La Vie r�v�e des ang...',\n",
       " '3515    Breathless (1983)',\n",
       " '3230    Hanging Up (2000)',\n",
       " '2320    Psycho (1998)',\n",
       " '2007    Blue Velvet (1986)',\n",
       " '1029    That Thing You Do! (1996)',\n",
       " '264    Major Payne (1994)']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, warp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
