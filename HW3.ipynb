{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "HW3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEXiKM2FW5PQ"
      },
      "source": [
        "### Homework 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_u96B0AW5PQ"
      },
      "source": [
        "* 1) найти датасет, обосновать\n",
        "* 2) построить MF, покрутить, построить метрики-симилары-рекоммендации\n",
        "* 3) построить NCF: покрутить, построить метрики-симилары-рекоммендации\n",
        "* 4) построить simple attention: покрутить, построить метрики-симилары-рекоммендации.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGQCHY0oW7Is",
        "outputId": "b388eb54-ee5a-4ba7-cf35-074e8909e7f6"
      },
      "source": [
        "!pip install rankfm\n",
        "!pip install lightfm\n",
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rankfm in /usr/local/lib/python3.6/dist-packages (0.2.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from rankfm) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from rankfm) (1.1.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->rankfm) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->rankfm) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->rankfm) (1.15.0)\n",
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.6/dist-packages (1.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightfm) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightfm) (0.17.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSrHrWLDW5PQ"
      },
      "source": [
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import wget\n",
        "import os\n",
        "import zipfile\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "from rankfm.rankfm import RankFM\n",
        "from rankfm.evaluation import hit_rate, discounted_cumulative_gain, precision, recall\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from  torch.utils.data import DataLoader\n",
        "from lightfm import LightFM\n",
        "from sklearn.metrics import ndcg_score\n",
        "from torch.optim import Adam, SGD\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdujs4uKX_dX"
      },
      "source": [
        "link = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "\n",
        "wget.download(link)\n",
        "\n",
        "with zipfile.ZipFile('ml-1m.zip',\"r\") as zip_ref:\n",
        "    zip_ref.extractall(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj-gMCVxYNzA"
      },
      "source": [
        "os.chdir('ml-1m')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwM1a-jgYe9W"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdBBBLpUW5PR"
      },
      "source": [
        "### 1. DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhvrn4IkW5PR"
      },
      "source": [
        "В качества датасета взяла movieLens потому что:\n",
        "* Уже достаточно знакома с этим датасетом по 1 - дз, есть параметры на которые оритентироваться при обучении WARP\n",
        "* Интуитивно понятно качество модели по выданным айтемам\n",
        "* Достаточно популярный датасет, используемый во многих статьях, в том числе в Neural Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NffFsl5EByZ"
      },
      "source": [
        "Метрики будем смотреть как в статье - NDCG и HR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykB22fkCW5PR"
      },
      "source": [
        "ratings = pd.read_csv('ratings.dat', delimiter='::', header=None, \n",
        "        names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
        "        usecols=['user_id', 'movie_id', 'rating'], engine='python')\n",
        "movie_info = pd.read_csv('movies.dat', delimiter='::', header=None, \n",
        "        names=['movie_id', 'name', 'category'], engine='python')\n",
        "ratings = ratings.loc[ratings['rating'] >= 4]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxFE27SZW5PR"
      },
      "source": [
        "users = np.unique(ratings[\"user_id\"])\n",
        "items = np.unique(ratings[\"movie_id\"])\n",
        "\n",
        "users_dict, items_dict = {i: j for j, i in enumerate(users)}, {i: j for j, i in enumerate(items)}\n",
        "inv_users_dict, inv_items_dict =  {i: j for j, i in users_dict.items()}, {i: j for j, i in items_dict.items()}\n",
        "\n",
        "new_users, new_items = ratings['user_id'].apply(lambda i: users_dict[i]), ratings['movie_id'].apply(lambda i: items_dict[i])\n",
        "\n",
        "implicit = pd.concat([new_users, new_items], axis=1).to_numpy()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e6p75c-W5PR"
      },
      "source": [
        "get_similars = lambda item_id, model : [movie_info[movie_info[\"movie_id\"] == inv_items_dict[x]][\"name\"].to_string()\n",
        "                                        for x in model.similar_items(items_dict[item_id])]\n",
        "\n",
        "get_recommendations = lambda user_id, model: [movie_info[movie_info[\"movie_id\"] == inv_items_dict[x]][\"name\"].to_string()\n",
        "                                                   for x in model.recommend([users_dict[user_id]]).values[0]]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ygViZYkW5PR"
      },
      "source": [
        "def metrics(model, dataset, n=500, k=10):\n",
        "    NDCG, HR = [], []  \n",
        "    labels = np.array([1] + (n-1)*[0])\n",
        "    for user_item in tqdm(dataset.test, position=0, leave=False):\n",
        "        user = user_item[0]\n",
        "        negatives = np.column_stack([np.full(n-1, user), np.random.choice(dataset.user_neg[user],n-1, replace=False)])\n",
        "        \n",
        "        predictions = model.predict(np.append([user_item], negatives, axis=0))\n",
        "        predictions = np.nan_to_num(predictions)\n",
        "\n",
        "        NDCG.append(ndcg_score([labels], [predictions], k=k))\n",
        "        HR.append(np.sum(np.argsort(-predictions)[:k] == 0))\n",
        "\n",
        "    print(f\"NDCG@{k}: {np.mean(NDCG):2f}\")\n",
        "    print(f\"HR@k{k}: {np.mean(HR):2f}\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olQ1CnI6W5PR"
      },
      "source": [
        "class Data:\n",
        "    def __init__(self, dataset):\n",
        "        self.data = dataset\n",
        "        self.n_users = dataset[:, 0].max() + 1\n",
        "        self.n_items = dataset[:, 1].max() + 1\n",
        "        self.compute_pos_neg()\n",
        "        self.train_test_split()\n",
        "        self.create_train_dataset()\n",
        "\n",
        "        \n",
        "    def compute_pos_neg(self):\n",
        "        self.user_neg = {}\n",
        "        for u in tqdm(range(self.n_users), position=0, leave=False):        \n",
        "            user_pos_items = self.data[self.data[:, 0] == u][:, 1]\n",
        "            user_neg_items = list(set(np.arange(self.n_items)) - set(user_pos_items))\n",
        "            self.user_neg[u] = user_neg_items\n",
        "            \n",
        "    def train_test_split(self): \n",
        "        train, test = np.array([]), np.array([])\n",
        "        for u in tqdm(range(self.n_users), position=0, leave=False): \n",
        "            watched = self.data[self.data[:, 0] == u]\n",
        "            train = np.append(train, watched[:-1])\n",
        "            test = np.append(test, watched[-1])\n",
        "        self.test = test.reshape(-1, 2).astype(int)\n",
        "        self.train = train.reshape(-1, 2).astype(int)\n",
        "\n",
        "    def create_train_dataset(self, n_negatives=5):\n",
        "        self.users, self.items, self.labels = [], [], []\n",
        "        for u in tqdm(range(self.n_items), position=0, leave=False): \n",
        "            positives = n_negatives * list(self.train[self.train[:,0] == u][:, 1])\n",
        "            negatives = list(np.random.choice(self.user_neg[u], len(positives)))\n",
        "            self.users.extend([u]*(len(positives) + len(negatives)))\n",
        "            self.items.extend(positives + negatives)\n",
        "            self.labels.extend([1]*len(positives) + [0]*len(negatives))\n",
        "        self.dataset = np.stack([self.users, self.items, self.labels], axis=1)\n",
        "     \n",
        "    def __getitem__(self, idx):\n",
        "        return (*self.dataset[idx],)   \n",
        "             \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy2Jo-9TW5PR",
        "outputId": "3c08f469-dcde-49bc-d585-4365b0ef84f4"
      },
      "source": [
        "dataset = Data(implicit)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9o3Sw2QW5PR"
      },
      "source": [
        "### 2. WARP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moIrESWSW5PR"
      },
      "source": [
        "warp = RankFM(factors=30,\n",
        "               loss='warp',\n",
        "               max_samples=20,\n",
        "               learning_rate=1e-1,\n",
        "               learning_schedule='invscaling')\n",
        "warp.fit(dataset.train, epochs=55)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBLQVamPW5PR",
        "outputId": "d877a22c-3a4a-41a5-9041-1ef12bd8b52c"
      },
      "source": [
        "get_similars(1, warp)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['584    Aladdin (1992)',\n",
              " '3045    Toy Story 2 (1999)',\n",
              " '591    Beauty and the Beast (1991)',\n",
              " '360    Lion King, The (1994)',\n",
              " '1838    Mulan (1998)',\n",
              " '1132    Wrong Trousers, The (1993)',\n",
              " '1205    Grand Day Out, A (1992)',\n",
              " '735    Close Shave, A (1995)',\n",
              " \"2286    Bug's Life, A (1998)\",\n",
              " '1526    Hercules (1997)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFoOA0tZW5PR",
        "outputId": "8679bdc2-88e6-422e-ed90-80fd8eb0422d"
      },
      "source": [
        "get_recommendations(4, warp)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1196    Alien (1979)',\n",
              " '1180    Raiders of the Lost Ark (1981)',\n",
              " '847    Godfather, The (1972)',\n",
              " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
              " '2502    Matrix, The (1999)',\n",
              " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
              " '1183    Good, The Bad and The Ugly, The (1966)',\n",
              " '1203    Godfather: Part II, The (1974)',\n",
              " '1023    Die Hard (1988)',\n",
              " '1366    Jaws (1975)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ovmpBfiSa6N",
        "outputId": "702ea837-4c0d-4c23-882d-b5b61210a2e1"
      },
      "source": [
        "hit_rate(warp, dataset.test)\n",
        "    "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0399204903097565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_TrYTENhld4",
        "outputId": "1eb8fdc9-e1d3-4834-f7e7-46a9fbcf5ee3"
      },
      "source": [
        "discounted_cumulative_gain(warp, dataset.test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01873986131435244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvVTgZiUj4Gs",
        "outputId": "db1559e7-dfa8-4927-d3e2-2f861267d79e"
      },
      "source": [
        "precision(warp, dataset.test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00399204903097565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFI6S8vjp0HR",
        "outputId": "4a68b454-9fc8-4a09-dc92-15c5c37f087d"
      },
      "source": [
        "metrics(warp, dataset)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NDCG@10: 0.201512\n",
            "HR@k10: 0.379430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwiE-pIIETqb"
      },
      "source": [
        "Рекомендации и симилары хорошие\n",
        "Встроенные метрики считаются немного подругому поэтому они различаются, но все равно хотелось на них посмотреть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7RJq9POESlW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLpgJonuW5PS"
      },
      "source": [
        "### 3. NCF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z3dE5PQW5PS"
      },
      "source": [
        "В статье наибольшие значения метрик достигаются при конкатенции предобученных эмбедингов MLP и GMF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzZ1FCiyW5PS"
      },
      "source": [
        "class Base(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "              \n",
        "    def fit(self): \n",
        "        \n",
        "        if self.optimizer_type ==\"Adam\":\n",
        "            optimizer = Adam(self.parameters(), lr=self.lr)\n",
        "        elif self.optimizer_type ==\"SGD\":\n",
        "            optimizer = SGD(self.parameters(), lr=self.lr)\n",
        "        \n",
        "        criterion = nn.BCELoss()\n",
        "        bar = tqdm(total=self.epochs, position=0,leave=False, desc='')\n",
        "        \n",
        "        for epoch in range(self.epochs):\n",
        "            self.data.create_train_dataset(n_negatives=5)\n",
        "            L_epoch = 0\n",
        "            train_loader = DataLoader(self.data, batch_size=self.batch_size, shuffle=True) \n",
        "            \n",
        "            for batch in train_loader:\n",
        "                \n",
        "                users, items, labels = batch\n",
        "                users = users.to(device)\n",
        "                items = items.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = self.forward(users, items)\n",
        "\n",
        "                L = criterion(outputs, labels.float().view(-1, 1))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                L.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                L_epoch += L.item()\n",
        "           \n",
        "            bar.update(1)\n",
        "            bar.set_description(f'Loss: {L_epoch:.2f}')\n",
        "#             print(self.rmse())\n",
        "        self.embeddings()\n",
        "        \n",
        "            \n",
        "    def embeddings(self):       \n",
        "        if self.model_type in ('MLP', 'GMF'):\n",
        "            self.items_embedding_w = self.embedding_item.weight.data.cpu().numpy()\n",
        "            self.users_embedding_w = self.embedding_user.weight.data.cpu().numpy()\n",
        "        elif self.model_type in ('NCF'):\n",
        "            self.cat_embeddings()\n",
        "\n",
        "    def similar_items(self, item_id, k=10):\n",
        "        \"\"\"\n",
        "        Get similar items for item_id according to fitted embeddings \n",
        "        \"\"\"\n",
        "        predicted_ratings = self.items_embedding_w @ self.items_embedding_w[item_id] / np.linalg.norm(self.items_embedding_w, axis=-1)\n",
        "        idx_similars = np.argsort(-predicted_ratings)\n",
        "        return idx_similars[:k]\n",
        "\n",
        "    def recommend(self, user_id, k=10):\n",
        "        \"\"\"\n",
        "        Recommend users new items which he didn't look before \n",
        "        \"\"\"\n",
        "        unwatched = np.array(self.data.user_neg[user_id[0]])\n",
        "        negatives = np.column_stack([np.full(len(unwatched), user_id), unwatched])\n",
        "        predicted_ratings = self.predict(negatives)\n",
        "        idx_recommendations = unwatched[np.argsort(-predicted_ratings)]\n",
        "        return pd.DataFrame(idx_recommendations[:k].reshape(1, -1))\n",
        "    \n",
        "    def predict(self, user_item, cold_start=None):\n",
        "        predictions = np.array([])\n",
        "        loader = DataLoader(user_item, batch_size=self.batch_size)\n",
        "        with torch.no_grad():\n",
        "            for u_i in loader:\n",
        "                u = u_i[:, 0].to(device).long()\n",
        "                i = u_i[:, 1].to(device).long()\n",
        "                predictions = np.append(predictions, self.forward(u, i).cpu().numpy().squeeze())\n",
        "        return predictions\n",
        "        "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdGGRLhaW5PS"
      },
      "source": [
        "class Model(Base):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.model_type = args[\"model_type\"]\n",
        "        self.optimizer_type = args[\"optimizer_type\"]\n",
        "        self.lr, self.batch_size, self.epochs = args[\"lr\"], args[\"batch_size\"], args[\"epochs\"]\n",
        "        self.data = args[\"data\"]\n",
        "        \n",
        "        self.embedding_user = nn.Embedding(num_embeddings=self.data.n_users, embedding_dim=args[\"embedding_dim\"])\n",
        "        self.embedding_item = nn.Embedding(num_embeddings=self.data.n_items, embedding_dim=args[\"embedding_dim\"])\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "        if self.model_type == 'MLP':\n",
        "            self.MLP = nn.Sequential(nn.Linear(2 * args[\"embedding_dim\"], 128),\n",
        "                                     nn.ReLU(), \n",
        "                                     nn.Linear(128, 64), \n",
        "                                     nn.ReLU(), \n",
        "                                     nn.Linear(64, 32),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(32, 16),\n",
        "                                     nn.ReLU())\n",
        "            self.output =  nn.Linear(16, 1)\n",
        "        elif self.model_type == 'GMF':\n",
        "            self.output =  nn.Linear(args[\"embedding_dim\"], 1)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "    \n",
        "\n",
        "    def forward(self, user_id, item_id, forward_type='full_model'):\n",
        "        \n",
        "        if self.model_type == 'MLP':\n",
        "            out = torch.cat([self.embedding_user(user_id), self.embedding_item(item_id)], dim=-1)\n",
        "            out = self.MLP(out)\n",
        "            if forward_type == 'full_model':\n",
        "                return self.sigm(self.output(out))\n",
        "            return out\n",
        "        \n",
        "        elif self.model_type == 'GMF':\n",
        "            out = torch.mul(self.embedding_user(user_id), self.embedding_item(item_id))\n",
        "            if forward_type == 'full_model':\n",
        "                return self.sigm(self.output(out))\n",
        "            return out\n",
        "        else:\n",
        "            raise NotImplementedError"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVibSKGWW5PS"
      },
      "source": [
        "class NCF(Base):\n",
        "    def __init__(self, args, pretrained_mlp, pretrained_gmf):\n",
        "        super().__init__()\n",
        "        self.model_type = args[\"model_type\"]\n",
        "        self.optimizer_type = args[\"optimizer_type\"]\n",
        "        self.lr, self.batch_size, self.epochs = args[\"lr\"], args[\"batch_size\"], args[\"epochs\"]\n",
        "        self.data= args[\"data\"]\n",
        "        \n",
        "        self.alpha = args['alpha']\n",
        "\n",
        "        self.pretrained_MLP = pretrained_mlp\n",
        "        self.pretrained_GMF = pretrained_gmf\n",
        "        \n",
        "        self.output = nn.Linear(pretrained_mlp.__dict__['_modules']['output'].in_features\n",
        "                                + pretrained_gmf.__dict__['_modules']['output'].in_features, 1)\n",
        "    \n",
        "    \n",
        "    def forward(self, user_id, item_id):\n",
        "        mlp_rating = self.pretrained_MLP.forward(user_id, item_id, forward_type='compound')\n",
        "        gmf_rating = self.pretrained_GMF.forward(user_id, item_id,  forward_type='compound')\n",
        "        rating = torch.cat([self.alpha * gmf_rating, (1 - self.alpha) * mlp_rating], dim=-1)\n",
        "        return torch.sigmoid(self.output(rating)) \n",
        "\n",
        "    def cat_embeddings(self):\n",
        "        self.items_embedding_w = torch.cat([self.alpha * self.pretrained_GMF.embedding_item.weight.data.cpu(), (1 - self.alpha)*self.pretrained_MLP.embedding_item.weight.data.cpu()], dim=-1).numpy()\n",
        "        self.users_embedding_w = torch.cat([self.alpha * self.pretrained_GMF.embedding_user.weight.data.cpu(), (1 - self.alpha)*self.pretrained_MLP.embedding_user.weight.data.cpu()], dim=-1).numpy()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGUdJZZHW5PS"
      },
      "source": [
        "\n",
        "mlp_parametrs = {\"data\": dataset,\n",
        "                 \"embedding_dim\": 64,\n",
        "                 \"hidden_dim\": 64,\n",
        "                 \"lr\":1e-2, \n",
        "                 \"batch_size\":512,\n",
        "                 \"epochs\": 10,\n",
        "                 \"optimizer_type\": \"Adam\",\n",
        "                 \"model_type\" : 'MLP'}\n",
        "\n",
        "gmf_parametrs = {\"data\": dataset,\n",
        "                 \"embedding_dim\": 64,\n",
        "                 \"hidden_dim\": 64,\n",
        "                 \"lr\":1e-2, \n",
        "                 \"batch_size\":256,\n",
        "                 \"epochs\": 30,\n",
        "                 \"optimizer_type\": \"Adam\",\n",
        "                 \"model_type\" : 'GMF'}"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv5o9KuKW5PS",
        "outputId": "999b6b40-4965-4450-d1f3-aa54ef6108c1"
      },
      "source": [
        "mlp = Model(mlp_parametrs).to(device)\n",
        "mlp.fit()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 1309.58: 100%|██████████| 10/10 [06:09<00:00, 36.71s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G91YVbaBW5PS",
        "outputId": "439f23b7-9e5c-4573-cd9e-a6323fe5cff0"
      },
      "source": [
        "get_similars(1, mlp)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0    Toy Story (1995)',\n",
              " '33    Babe (1995)',\n",
              " '3045    Toy Story 2 (1999)',\n",
              " '1245    Groundhog Day (1993)',\n",
              " '1250    Back to the Future (1985)',\n",
              " '352    Forrest Gump (1994)',\n",
              " '1179    Princess Bride, The (1987)',\n",
              " '360    Lion King, The (1994)',\n",
              " '584    Aladdin (1992)',\n",
              " '257    Star Wars: Episode IV - A New Hope (1977)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQe4tj4jW5PS",
        "outputId": "2db95821-bab9-4cc4-a29c-61f857fd5f7c"
      },
      "source": [
        "get_recommendations(4, mlp)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
              " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
              " '1182    Aliens (1986)',\n",
              " '1353    Star Trek: The Wrath of Khan (1982)',\n",
              " '585    Terminator 2: Judgment Day (1991)',\n",
              " '847    Godfather, The (1972)',\n",
              " '108    Braveheart (1995)',\n",
              " '1267    Ben-Hur (1959)',\n",
              " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
              " '1204    Full Metal Jacket (1987)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jotcPeBaW5PS",
        "outputId": "81b14576-a9fb-4f3a-bb5b-56bfbcdbb664"
      },
      "source": [
        "metrics(mlp, dataset)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NDCG@10: 0.156559\n",
            "HR@k10: 0.296621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFUZKnLxW5PS"
      },
      "source": [
        "gmf = Model(gmf_parametrs).to(device)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjEacTHqAYed",
        "outputId": "ace79641-1f43-4989-9bc9-ac339b2a59fd"
      },
      "source": [
        "gmf.fit()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2280.41: 100%|██████████| 30/30 [17:55<00:00, 35.90s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS3JD5xyW5PT",
        "outputId": "a5c4647f-0a2b-441c-c908-ef4e927e871b"
      },
      "source": [
        "get_similars(1, gmf)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0    Toy Story (1995)',\n",
              " '3045    Toy Story 2 (1999)',\n",
              " \"2286    Bug's Life, A (1998)\",\n",
              " '584    Aladdin (1992)',\n",
              " '2252    Pleasantville (1998)',\n",
              " '360    Lion King, The (1994)',\n",
              " '591    Beauty and the Beast (1991)',\n",
              " '33    Babe (1995)',\n",
              " '1245    Groundhog Day (1993)',\n",
              " '1179    Princess Bride, The (1987)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaUiZ-NfW5PT",
        "outputId": "e741e99b-01b9-4579-86d7-0ea352b79dc0"
      },
      "source": [
        "get_recommendations(4, gmf)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
              " '2502    Matrix, The (1999)',\n",
              " '1267    Ben-Hur (1959)',\n",
              " '585    Terminator 2: Judgment Day (1991)',\n",
              " '847    Godfather, The (1972)',\n",
              " '453    Fugitive, The (1993)',\n",
              " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
              " '740    Dr. Strangelove or: How I Learned to Stop Worr...',\n",
              " '1203    Godfather: Part II, The (1974)',\n",
              " '1271    Indiana Jones and the Last Crusade (1989)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvKBFQrzyIE1",
        "outputId": "6411e9f3-7f30-4220-c8dd-0765faaf177c"
      },
      "source": [
        "metrics(gmf, dataset)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NDCG@10: 0.092125\n",
            "HR@k10: 0.183504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe2mzATIW5PT"
      },
      "source": [
        "ncf_parametrs = {\"data\": dataset,\n",
        "                 \"lr\":1e-2, \n",
        "                 \"batch_size\":512,\n",
        "                 \"epochs\": 10,\n",
        "                 \"optimizer_type\": \"SGD\",\n",
        "                 \"alpha\": 0.5,\n",
        "                 \"model_type\" : 'NCF'}"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5T3601tW5PT",
        "outputId": "f5169110-861a-46ce-9142-2b8d1dc3e902"
      },
      "source": [
        "ncf = NCF(ncf_parametrs, mlp, gmf).to(device)\n",
        "ncf.fit()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 775.59: 100%|██████████| 10/10 [05:23<00:00, 32.28s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR9tO33PW5PT",
        "outputId": "94927588-46fa-4e27-9371-25abbdb213f9"
      },
      "source": [
        "get_similars(1, ncf)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0    Toy Story (1995)',\n",
              " '3045    Toy Story 2 (1999)',\n",
              " '33    Babe (1995)',\n",
              " '1245    Groundhog Day (1993)',\n",
              " '584    Aladdin (1992)',\n",
              " '1179    Princess Bride, The (1987)',\n",
              " '360    Lion King, The (1994)',\n",
              " '1250    Back to the Future (1985)',\n",
              " '352    Forrest Gump (1994)',\n",
              " '591    Beauty and the Beast (1991)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIDshRvsW5PT",
        "outputId": "6886379d-021b-4ce4-cf03-810c059ad4fc"
      },
      "source": [
        "get_recommendations(4, ncf)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
              " '1267    Ben-Hur (1959)',\n",
              " '847    Godfather, The (1972)',\n",
              " '585    Terminator 2: Judgment Day (1991)',\n",
              " '2502    Matrix, The (1999)',\n",
              " '453    Fugitive, The (1993)',\n",
              " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
              " '740    Dr. Strangelove or: How I Learned to Stop Worr...',\n",
              " '1203    Godfather: Part II, The (1974)',\n",
              " '1950    Seven Samurai (The Magnificent Seven) (Shichin...']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE12t4nRW5PT",
        "outputId": "d19ad19c-52ea-4c68-bdb2-e9aa894a4374"
      },
      "source": [
        "metrics(ncf, dataset)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NDCG@10: 0.127359\n",
            "HR@k10: 0.247764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qQ9iJ1xOMai"
      },
      "source": [
        "Не очень получилось, видимо где-то ошибка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht_JVe6iOM7r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}